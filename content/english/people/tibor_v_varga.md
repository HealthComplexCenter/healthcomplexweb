---
title: "Tibor V. Varga"
draft: false
# page title background image
bg_image: "images/backgrounds/page-title.jpg"
# meta description
description : "Meet our team"
# teacher portrait
image: "images/teachers/TiborVVarga.jpg"
# course
course: "Health Inequality"
# biography
bio: "This teacher was born in 1980 in New York. He has been teaching computer science for 10 years. He is a specialist in computer networking, computer security, and human-computer interfacing."
# interest
interest: ["Computer Networking","Computer Security","Human Computer Interfacing"]
# contact info
contact:
  # contact item loop
  - name : "Tibor.Varga@sund.ku.dk"
    icon : "ti-email" # icon pack : https://themify.me/themify-icons
    link : "mailto:Tibor.Varga@sund.ku.dk"

  # contact item loop
  - name : "+4535327739"
    icon : "ti-mobile" # icon pack : https://themify.me/themify-icons
    link : "tel:+4535327739"

  # contact item loop
  - name : "https://www.linkedin.com/in/tiborvvarga/"
    icon : "ti-linkedin" # icon pack : https://themify.me/themify-icons
    link : "https://www.linkedin.com/in/tiborvvarga/"

  # contact item loop
  - name : "https://github.com/Tirgit"
    icon : "ti-github" # icon pack : https://themify.me/themify-icons
    link : "https://github.com/Tirgit"

# type
type: "teacher"
---

### About Me

Using AI on prospective, life-course big data to fight social inequity and identify causal determinants of health and disease at the Section of Epidemiology at the University of Copenhagen.

The last decade experienced a huge increase in the utilization of AI algorithms in healthcare and elsewhere. Initial high hopes for AI to reduce various human biases have come to a halt as it became apparent that AI often further propagates biases that are deeply embedded in the data it uses. While math does not care about sex, gender, skin color, sexual preference, religion and country of origin, our societies are far from equal and there is a high risk that any data collection might be sensitive to inherent societal biases and downstream analyses might further propagate these into results, solutions, policies, applications, publications, and in many ways normalize these inequalities. We need to understand this process, talk about this issue and combat inequality from the start. We need to assess our available data for biases, we need to use AI to remove biases and carefully assess algorithms and any results for fairness. Hope to make a difference, hope to educate and to generate a public conversation!